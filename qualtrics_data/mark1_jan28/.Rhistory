res_11
res_12 <- t.test(BIPHON_subset_u_alt_ɯ$Correct,BIPHON_subset_u_alt_ø$Correct)
res_12
res_13 <- t.test(BIPHON_subset_ʊ_alt_ø$Correct,BIPHON_subset_ʊ_alt_ɯ$Correct)
res_13
library(readxl)
vowel_formants_reduced <- read_excel("Desktop/lab stuff/vowel_formants_reduced.xls")
View(vowel_formants_reduced)
library(ggplot2)
vowel_formants_reduced$vowel <- as.factor(vowel_formants_reduced$vowel)
ggplot(data=vowel_formants_reduced, aes(x=F2, y=F1)) +
geom_point(aes(color=vowel)) +
scale_x_reverse(position = "top") +
scale_y_reverse(position = "right")
ggplot(data=vowel_formants_reduced, aes(x=F2, y=F1)) +
geom_text(aes(label=vowel, color=vowel)) +
scale_x_reverse(position = "top") +
scale_y_reverse(position = "right")
ggplot(data=vowel_formants_reduced, aes(x=F2, y=F1)) +
geom_text(aes(label=vowel, color=vowel, size=14)) +
scale_x_reverse(position = "top") +
scale_y_reverse(position = "right")
ggplot(data=vowel_formants_reduced, aes(x=F2, y=F1)) +
geom_text(aes(label=vowel, color=vowel), size=12) +
scale_x_reverse(position = "top") +
scale_y_reverse(position = "right")
ggplot(data=vowel_formants_reduced, aes(x=F2, y=F1)) +
geom_text(aes(label=vowel, color=vowel), size=10) +
scale_x_reverse(position = "top") +
scale_y_reverse(position = "right")
ggplot(data=vowel_formants_reduced, aes(x=F2, y=F1)) +
geom_text(aes(label=vowel, color=vowel), size=10) +
scale_x_reverse(position = "top") +
scale_y_reverse(position = "right") + theme(title="Vowels")
ggplot(data=vowel_formants_reduced, aes(x=F2, y=F1)) +
geom_text(aes(label=vowel, color=vowel), size=10) +
scale_x_reverse(position = "top") +
scale_y_reverse(position = "right") + theme(title = Vowels)
ggplot(data=vowel_formants_reduced, aes(x=F2, y=F1)) +
geom_text(aes(label=vowel, color=vowel), size=10) +
scale_x_reverse(position = "top") +
scale_y_reverse(position = "right") + theme(title = 'Vowels'')
ggplot(data=vowel_formants_reduced, aes(x=F2, y=F1)) +
geom_text(aes(label=vowel, color=vowel), size=10) +
scale_x_reverse(position = "top") +
scale_y_reverse(position = "right")
ggplot(data=vowel_formants_reduced, aes(x=F2, y=F1)) +
geom_text(aes(label=vowel, color=vowel), size=10) +
scale_x_reverse(position = "top") +
scale_y_reverse(position = "right") + theme(title = 'Vowels'')
ggplot(data=vowel_formants_reduced, aes(x=F2, y=F1)) +
geom_text(aes(label=vowel, color=vowel), size=10) +
scale_x_reverse(position = "top") +
scale_y_reverse(position = "right") + theme(title = 'Vowels')
ggplot(data=vowel_formants_reduced, aes(x=F2, y=F1)) +
geom_text(aes(label=vowel, color=vowel), size=10) +
scale_x_reverse(position = "top") +
scale_y_reverse(position = "right") + theme(title = element_text('Vowels')
ggplot(data=vowel_formants_reduced, aes(x=F2, y=F1)) +
geom_text(aes(label=vowel, color=vowel), size=10) +
scale_x_reverse(position = "top") +
scale_y_reverse(position = "right") + theme(title = element_text('Vowels'))
ggplot(data=vowel_formants_reduced, aes(x=F2, y=F1)) +
geom_text(aes(label=vowel, color=vowel), size=10) +
scale_x_reverse(position = "top") +
scale_y_reverse(position = "right")
ggplot(data=vowel_formants_reduced, aes(x=F2, y=F1)) +
geom_text(aes(label=vowel, color=vowel), size=8) +
scale_x_reverse(position = "top") +
scale_y_reverse(position = "right")
library(readxl)
vowel_formants_reduced <- read_excel("Desktop/lab stuff/vowel_formants_reduced.xls")
View(vowel_formants_reduced)
ggplot(data=vowel_formants_reduced, aes(x=F2, y=F1)) +
geom_text(aes(label=vowel, color=vowel), size=8) +
scale_x_reverse(position = "top") +
scale_y_reverse(position = "right")
sig <- table(1,2)
sig
sig <- table(1,2,3)
sig
sig <- table(1,5)
sig
sig <- table(1:3,5)
BIPHON_subset_Yu <- subset(BIPHON3, critical_vowel_token == "ʏu")
BIPHON_subset_uY <- subset(BIPHON3, critical_vowel_token == "uʏ")
BIPHON_subset_u_alt_Y <- rbind(BIPHON_subset_Yu,BIPHON_subset_uY)
res_15 <- t.test(BIPHON_subset_u_alt_Y$Correct,BIPHON_subset_u_alt_y$Correct)
View(BIPHON_subset_uY)
View(BIPHON_subset_uY)
BIPHON3
BIPHON_subset_Yu <- subset(BIPHON3, critical_vowel_token == "ʏu")
BIPHON3$critical_vowel_token
library(readxl)
BIPHON3 <- read_excel("Desktop/lab stuff/BIPHON3_plusdist.xlsx")
View(BIPHON3)
BIPHON_native ,- subset(BIPHON3, Nativeness == "1")
BIPHON_native <- subset(BIPHON3, Nativeness == "1")
BIPHON_nonnative <- subset(BIPHON3, Nativeness == "0")
head(BIPHON3)
nonnative_mdl <- lmer(Correct ~ critical_vowel_distance +(1|Subject), data=BIPHON3)
library(lme4)
nonnative_mdl <- lmer(Correct ~ critical_vowel_distance +(1|Subject), data=BIPHON3)
nonnative_mdl <- lmer(Correct ~ critical_vowel_distance...30 +(1|Subject), data=BIPHON3)
nonnative_mdl <- lmer(Correct ~ critical_vowel_dist +(1|Subject), data=BIPHON3)
summary(nonnative_mdl)
nonnative_mdl <- lmer(Correct ~ critical_vowel_dist +(1|Subject), data=BIPHON3, family="binomial")
nonnative_mdl <- glmer(Correct ~ critical_vowel_dist +(1|Subject), data=BIPHON3, family="binomial")
str(BIPHON3)
BIPHON_nonnative$Correct = as.factor(BIPHON_nonnative$Correct)
str(BIPHON3)
str(BIPHON3_nonnative)
str(BIPHON_nonnative)
nonnative_mdl <- glmer(Correct ~ critical_vowel_dist +(1|Subject), data=BIPHON3, family="binomial")
View(BIPHON_nonnative)
nonnative_mdl <- glmer(Correct ~ critical_vowel_dist +(1|Subject), data=BIPHON3, family="logit")
nonnative_mdl <- glmer(Correct ~ critical_vowel_dist +(1|Subject), data=BIPHON3, family="binomial"(link='logit'))
library(lmerTest)
library(dplyr) # this checks for normality
library(ggpubr) # this plots normality
install.packages("ggpubr")
set.seed(1234)
dplyr::sample_n(BIPHON3, 15)
ggqqplot(BIPHON3$Correct) # make qq plot
library(ggpubr)
set.seed(1234)
dplyr::sample_n(BIPHON3, 15)
ggqqplot(BIPHON3$Correct) # make qq plot
set.seed(1234)
dplyr::sample_n(BIPHON3, 15)
ggqqplot(BIPHON3$critical_vowel_dist) # make qq plot
ggdensity(BIPHON3$critical_vowel_dist,  # make density plot
main = "Density plot of RT",
xlab = "Reaction Time")
shapiro.test(BIPHON3$critical_vowel_dist) # test distribution against normal distribution
nonnative_mdl <- glmer(Correct ~ critical_vowel_dist +(1|Subject), data=BIPHON3, family=binomial(l))
nonnative_mdl <- glmer(Correct ~ critical_vowel_dist +(1|Subject), data=BIPHON3, family=binomial(link=logit))
nonnative_mdl <- glmer(Correct ~ critical_vowel_dist +(1|Subject), data=BIPHON3, family=binomial(link="logit"))
str(BIPHON_nonnative)
nonnative_mdl <- glme(Correct ~ critical_vowel_dist, data=BIPHON3, family=binomial(link="logit"))
nonnative_mdl <- lme(Correct ~ critical_vowel_dist, data=BIPHON3, family=binomial(link="logit"))
nonnative_mdl <- glm(Correct ~ critical_vowel_dist, data=BIPHON3, family=binomial(link="logit"))
nonnative_mdl
summary(nonnative_mdl)
View(nonnative_mdl)
View(nonnative_mdl)
nonnative_mdl <- glmer(Correct ~ critical_vowel_dist +(1|Subject), data=BIPHON3, family=binomial(link="logit"), glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 100000)))
nonnative_mdl <- glm(Correct ~ critical_vowel_dist, data=BIPHON3, family=binomial(link="logit"))
anova(nonnative_mdl)
Anova(nonnative_mdl)
install.package('car')
install.packages('car')
library('car')
install.packages("openxlsx")
library('car')
Anova(nonnative_mdl)
nonnative_mdl <- glmer(Correct ~ critical_vowel_dist +(1|Subject), data=BIPHON3, family=binomial(link="logit"), glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e5)))
nonnative_mdl <- glmer(Correct ~ critical_vowel_dist, data=BIPHON3, family=binomial(link="logit"), glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e5)))
nonnative_mdl <- glmer(Correct ~ critical_vowel_dist + (1|Subject), data=BIPHON3, family=binomial(link="logit"), glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e5)))
str(BIPHON_nonnative)
BIPHON_nonnative$Subject = as.factor(BIPHON_nonnative$Subject)
nonnative_mdl <- glmer(Correct ~ critical_vowel_dist + (1|Subject), data=BIPHON3, family=binomial(link="logit"), glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e5)))
nonnative_mdl <- glmer(Correct ~ critical_vowel_dist + (1|Subject), data=BIPHON_nonnative, family=binomial(link="logit"), glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e5)))
nonnative_mdl <- glmer(Correct ~ critical_vowel_dist + (1|unique_id), data=BIPHON_nonnative, family=binomial(link="logit"), glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e5)))
str(BIPHON_nonnative)
BIPHON_nonnative$unique_id = as.factor(BIPHON_nonnative$unique_id)
nonnative_mdl <- glmer(Correct ~ critical_vowel_dist + (1|unique_id), data=BIPHON_nonnative, family=binomial(link="logit"), glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e5)))
ggplot(data=vowel_formants_reduced, aes(x=F2, y=F1)) +
geom_text(aes(label=vowel, color=vowel), size=8) +
scale_x_reverse(position = "top") +
scale_y_reverse(position = "right")
library(ggplot)
library(ggplot2)
library(ggplot)
ggplot(data=vowel_formants_reduced, aes(x=F2, y=F1)) +
geom_text(aes(label=vowel, color=vowel), size=8) +
scale_x_reverse(position = "top") +
scale_y_reverse(position = "right")
View(vowel_formants_reduced)
library(readxl)
vowel_formants_reduced_2 <- read_excel("Desktop/lab stuff/vowel_formants_reduced_2.xls")
View(vowel_formants_reduced_2)
ggplot(data=vowel_formants_reduced_2, aes(x=F2, y=F1)) +
geom_text(aes(label=vowel, color=vowel), size=8) +
scale_x_reverse(position = "top") +
scale_y_reverse(position = "right")
## Queer Speech Data Analysis and Visualization Treasure Trove
## Author: Ben Lang, blang@ucsd.edu
# library(lmerTest)
library(dplyr) # this checks for normality
# library(ggpubr) # this plots normality
library(magrittr)
# library(effects)
# library(ggplot2)
library(tidyr)
# library(scales)
library(reshape2)
# library(lme4)
# library(emmeans)
library(forcats)
library(psycho)
library(tibble)
library(janitor)
setwd('/Users/bcl/Documents/GitHub/queer_speech/qualtrics_data/mark1_jan28/')
queer = read.csv('queer-speech_February 1, 2022_22.51.csv')
#cleaning data down to just ratings, trial type, and stimulus ID
# queer <- subset(queer, Status == 0 | Status == "Response Type") # just for if there's people that don't complete the survey
queer <- select(queer, -contains(c("First.Click","Last.Click","Page.Submit","Click.Count"))) # remove all the time counts, can add in later if needed
# queer$Participant <- 1:nrow(queer)-1
queer <- select(queer, -c(StartDate, EndDate, ResponseId, UserLanguage, Consent, HC1, HC2, RecipientLastName, RecipientFirstName, RecipientEmail, ExternalReference, LocationLatitude, LocationLongitude, DistributionChannel, IPAddress, Progress, Status, Finished, RecordedDate, Duration..in.seconds.))
queer <- select(queer, -c(P1_1:P5_1)) # eliminate practice questions
queer <- select(queer, -c(D1:id)) # eliminate practice questions
# queer <- queer %>% relocate(D2:Q47, .before = 1)
# queer <- queer %>% relocate(Q56, .before = 1)
queer <- queer[-2,]
# queer[1,] <- gsub(".*- (.+) -.*", "\\1", queer[1,]) # works on iMac, for some reason not on laptop, supposed to just grab URLs
queer <- add_column(queer, Participant = 1:nrow(queer)-1, .before = 1)
View(queer)
queer_qid <- queer[-1,]
queer_qid_long <- queer_qid %>% gather(Qualtrics_Trial_Num, Rating, X1_Q36_1:X33_Q62_1)
View(queer_qid_long)
#queer[1,] <- queer %>% separate(X1_Q36_1:X33_Q62_1, Question, Token)
queer_stimname <- row_to_names(queer, row_number = 1)
View(queer_stimname)
options(stringsAsFactors=F)
# library(lmerTest)
library(dplyr) # this checks for normality
# library(ggpubr) # this plots normality
library(magrittr)
# library(effects)
# library(ggplot2)
library(tidyr)
# library(scales)
library(reshape2)
# library(lme4)
# library(emmeans)
library(forcats)
# library(psycho)
library(tibble)
library(janitor)
setwd('/Users/bcl/Documents/GitHub/queer_speech/qualtrics_data/mark1_jan28/')
queer = read.csv('queer-speech_February 1, 2022_22.51.csv')
#cleaning data down to just ratings, trial type, and stimulus ID
# queer <- subset(queer, Status == 0 | Status == "Response Type") # just for if there's people that don't complete the survey
queer <- select(queer, -contains(c("First.Click","Last.Click","Page.Submit","Click.Count"))) # remove all the time counts, can add in later if needed
# queer$Participant <- 1:nrow(queer)-1
queer <- select(queer, -c(StartDate, EndDate, ResponseId, UserLanguage, Consent, HC1, HC2, RecipientLastName, RecipientFirstName, RecipientEmail, ExternalReference, LocationLatitude, LocationLongitude, DistributionChannel, IPAddress, Progress, Status, Finished, RecordedDate, Duration..in.seconds.))
queer <- select(queer, -c(P1_1:P5_1)) # eliminate practice questions
queer <- select(queer, -c(D1:id)) # eliminate practice questions
# queer <- queer %>% relocate(D2:Q47, .before = 1)
# queer <- queer %>% relocate(Q56, .before = 1)
queer <- queer[-2,]
# queer[1,] <- gsub(".*- (.+) -.*", "\\1", queer[1,]) # works on iMac, for some reason not on laptop, supposed to just grab URLs
queer <- add_column(queer, Participant = 1:nrow(queer)-1, .before = 1)
queer_qid <- queer[-1,]
queer_qid_long <- queer_qid %>% gather(Qualtrics_Trial_Num, Rating, X1_Q36_1:X33_Q62_1)
#queer[1,] <- queer %>% separate(X1_Q36_1:X33_Q62_1, Question, Token)
queer_stimname <- row_to_names(queer, row_number = 1)
View(queer_stimname)
setwd('/Users/bcl/Documents/GitHub/queer_speech/qualtrics_data/mark1_jan28/')
queer = read.csv('queer-speech_February 1, 2022_22.51.csv')
#cleaning data down to just ratings, trial type, and stimulus ID
# queer <- subset(queer, Status == 0 | Status == "Response Type") # just for if there's people that don't complete the survey
queer <- select(queer, -contains(c("First.Click","Last.Click","Page.Submit","Click.Count"))) # remove all the time counts, can add in later if needed
# queer$Participant <- 1:nrow(queer)-1
queer <- select(queer, -c(StartDate, EndDate, ResponseId, UserLanguage, Consent, HC1, HC2, RecipientLastName, RecipientFirstName, RecipientEmail, ExternalReference, LocationLatitude, LocationLongitude, DistributionChannel, IPAddress, Progress, Status, Finished, RecordedDate, Duration..in.seconds.))
queer <- select(queer, -c(P1_1:P5_1)) # eliminate practice questions
queer <- select(queer, -c(D1:id)) # eliminate practice questions
# queer <- queer %>% relocate(D2:Q47, .before = 1)
# queer <- queer %>% relocate(Q56, .before = 1)
queer <- queer[-2,]
queer[1,] <- gsub(".*- (.+) -.*", "\\1", queer[1,]) # works on iMac, for some reason not on laptop, supposed to just grab URLs
queer <- add_column(queer, Participant = 1:nrow(queer)-1, .before = 1)
# splitting dfs to then concatenate
queer_qid <- queer[-1,]
queer_qid_long <- queer_qid %>% gather(Qualtrics_Trial_Num, Rating, X1_Q36_1:X33_Q62_1)
#queer[1,] <- queer %>% separate(X1_Q36_1:X33_Q62_1, Question, Token)
queer_stimname <- row_to_names(queer, row_number = 1)
View(queer_stimname)
names(queer_stimname)[names(queer_stimname) == '0'] <- 'Participant'
View(queer_stimname)
View(queer_stimname)
queer_stimname %>% group_by(queer[1,])
queer_stimname %>% group_by(queer[0,])
queer_stimname %>% group_by(queer[1])
queer[1,]
queer_stimname %>% group_by(queer[1,]) %>% mutate(grouped_id = row_number())
queer_stimname %>% group_by(queer[1,]) %>% mutate(grouped_id = col_number())
queer_stimname %>% group_by(queer[1,]) %>% mutate(grouped_id = row_number())
queer_stimname_long <- queer_stimname %>% gather(Trial_Type, Rating, -Participant)
row_number()
queer_stimname %>% group_by(queer[1,]) %>% mutate(grouped_id = row_number(Participant))
queer_stimname_long <- queer_stimname %>% gather(Trial_Type, Rating, -Participant)
rep(1:3, each 3)
rep(1:3, each 3, length.out=20)
rep(1:3, each=3, length.out=20)
rep(1:3, each=1, length.out=20)
rep(1:3, each=1, length.out=queer[1,])
rep(1:3, each=1, length.out=len(queer[1,]))
rep(1:3, each=1, length.out=ncol(queer_stimname)))
rep(1:3, each=1, length.out=ncol(queer_stimname))
queer_stimname %>% mutate(Participant = row_number()) %>% gather(Trial_Type, Rating)
queer_stimname %>% pivot_long(-Participant)
## Queer Speech Data Analysis and Visualization Treasure Trove
## Author: Ben Lang, blang@ucsd.edu
# library(lmerTest)
library(dplyr) # this checks for normality
# library(ggpubr) # this plots normality
library(magrittr)
# library(effects)
# library(ggplot2)
library(tidyr)
# library(scales)
library(reshape2)
# library(lme4)
# library(emmeans)
library(forcats)
# library(psycho)
library(tibble)
library(janitor)
setwd('/Users/bcl/Documents/GitHub/queer_speech/qualtrics_data/mark1_jan28/')
queer = read.csv('queer-speech_February 1, 2022_22.51.csv')
#cleaning data down to just ratings, trial type, and stimulus ID
# queer <- subset(queer, Status == 0 | Status == "Response Type") # just for if there's people that don't complete the survey
queer <- select(queer, -contains(c("First.Click","Last.Click","Page.Submit","Click.Count"))) # remove all the time counts, can add in later if needed
# queer$Participant <- 1:nrow(queer)-1
queer <- select(queer, -c(StartDate, EndDate, ResponseId, UserLanguage, Consent, HC1, HC2, RecipientLastName, RecipientFirstName, RecipientEmail, ExternalReference, LocationLatitude, LocationLongitude, DistributionChannel, IPAddress, Progress, Status, Finished, RecordedDate, Duration..in.seconds.))
queer <- select(queer, -c(P1_1:P5_1)) # eliminate practice questions
queer <- select(queer, -c(D1:id)) # eliminate practice questions
# queer <- queer %>% relocate(D2:Q47, .before = 1)
# queer <- queer %>% relocate(Q56, .before = 1)
queer <- queer[-2,]
queer[1,] <- gsub(".*- (.+) -.*", "\\1", queer[1,]) # works on iMac, for some reason not on laptop, supposed to just grab URLs
queer <- add_column(queer, Participant = 1:nrow(queer)-1, .before = 1)
# splitting dfs to then concatenate
queer_qid <- queer[-1,]
queer_qid_long <- queer_qid %>% gather(Qualtrics_Trial_Num, Rating, X1_Q36_1:X33_Q62_1)
#queer[1,] <- queer %>% separate(X1_Q36_1:X33_Q62_1, Question, Token)
queer_stimname <- row_to_names(queer, row_number = 1)
names(queer_stimname)[names(queer_stimname) == '0'] <- 'Participant'
## Queer Speech Data Analysis and Visualization Treasure Trove
## Author: Ben Lang, blang@ucsd.edu
# library(lmerTest)
library(dplyr) # this checks for normality
# library(ggpubr) # this plots normality
library(magrittr)
# library(effects)
# library(ggplot2)
library(tidyr)
# library(scales)
library(reshape2)
# library(lme4)
# library(emmeans)
library(forcats)
# library(psycho)
library(tibble)
library(janitor)
setwd('/Users/bcl/Documents/GitHub/queer_speech/qualtrics_data/mark1_jan28/')
queer = read.csv('queer-speech_February 1, 2022_22.51.csv')
#cleaning data down to just ratings, trial type, and stimulus ID
# queer <- subset(queer, Status == 0 | Status == "Response Type") # just for if there's people that don't complete the survey
queer <- select(queer, -contains(c("First.Click","Last.Click","Page.Submit","Click.Count"))) # remove all the time counts, can add in later if needed
# queer$Participant <- 1:nrow(queer)-1
queer <- select(queer, -c(StartDate, EndDate, ResponseId, UserLanguage, Consent, HC1, HC2, RecipientLastName, RecipientFirstName, RecipientEmail, ExternalReference, LocationLatitude, LocationLongitude, DistributionChannel, IPAddress, Progress, Status, Finished, RecordedDate, Duration..in.seconds.))
queer <- select(queer, -c(P1_1:P5_1)) # eliminate practice questions
queer <- select(queer, -c(D1:id)) # eliminate practice questions
# queer <- queer %>% relocate(D2:Q47, .before = 1)
# queer <- queer %>% relocate(Q56, .before = 1)
queer <- queer[-2,]
queer[1,] <- gsub(".*- (.+) -.*", "\\1", queer[1,]) # works on iMac, for some reason not on laptop, supposed to just grab URLs
queer <- add_column(queer, Participant = 1:nrow(queer)-1, .before = 1)
# splitting dfs to then concatenate
queer_qid <- queer[-1,]
queer_qid_long <- queer_qid %>% gather(Qualtrics_Trial_Num, Rating, X1_Q36_1:X33_Q62_1)
#queer[1,] <- queer %>% separate(X1_Q36_1:X33_Q62_1, Question, Token)
queer_stimname <- row_to_names(queer, row_number = 1)
names(queer_stimname)[names(queer_stimname) == '0'] <- 'Participant'
## Queer Speech Data Analysis and Visualization Treasure Trove
## Author: Ben Lang, blang@ucsd.edu
# library(lmerTest)
library(dplyr) # this checks for normality
# library(ggpubr) # this plots normality
library(magrittr)
# library(effects)
# library(ggplot2)
library(tidyr)
# library(scales)
library(reshape2)
# library(lme4)
# library(emmeans)
library(forcats)
# library(psycho)
library(tibble)
library(janitor)
setwd('/Users/bcl/Documents/GitHub/queer_speech/qualtrics_data/mark1_jan28/')
queer = read.csv('queer-speech_February 1, 2022_22.51.csv')
#cleaning data down to just ratings, trial type, and stimulus ID
# queer <- subset(queer, Status == 0 | Status == "Response Type") # just for if there's people that don't complete the survey
queer <- select(queer, -contains(c("First.Click","Last.Click","Page.Submit","Click.Count"))) # remove all the time counts, can add in later if needed
# queer$Participant <- 1:nrow(queer)-1
queer <- select(queer, -c(StartDate, EndDate, ResponseId, UserLanguage, Consent, HC1, HC2, RecipientLastName, RecipientFirstName, RecipientEmail, ExternalReference, LocationLatitude, LocationLongitude, DistributionChannel, IPAddress, Progress, Status, Finished, RecordedDate, Duration..in.seconds.))
queer <- select(queer, -c(P1_1:P5_1)) # eliminate practice questions
queer <- select(queer, -c(D1:id)) # eliminate practice questions
# queer <- queer %>% relocate(D2:Q47, .before = 1)
# queer <- queer %>% relocate(Q56, .before = 1)
queer <- queer[-2,]
queer[1,] <- gsub(".*- (.+) -.*", "\\1", queer[1,]) # works on iMac, for some reason not on laptop, supposed to just grab URLs
queer <- add_column(queer, Participant = 1:nrow(queer)-1, .before = 1)
# splitting dfs to then concatenate
queer_qid <- queer[-1,]
queer_qid_long <- queer_qid %>% gather(Qualtrics_Trial_Num, Rating, X1_Q36_1:X33_Q62_1)
#queer[1,] <- queer %>% separate(X1_Q36_1:X33_Q62_1, Question, Token)
queer_stimname <- row_to_names(queer, row_number = 1)
names(queer_stimname)[names(queer_stimname) == '0'] <- 'Participant'
melt()?
?melt()
queer_stimname %>% melt()
queer_stimname_long <- queer_stimname %>% melt()
View(queer_stimname_long)
queer_stimname_long <- queer_stimname %>% melt(id = Participant)
queer_stimname_long <- queer_stimname %>% melt(value.name = "Trial_type")
queer_stimname_long <- queer_stimname %>% melt(meas = patterns("https://ucsd.co1.qualtrics.com/WRQualtricsControlPanel/File.php?F=F_bpk3XPtzPK8npH0",
"https://ucsd.co1.qualtrics.com/WRQualtricsControlPanel/File.php?F=F_es2YcbbCLrtMSmW",
"https://ucsd.co1.qualtrics.com/WRQualtricsControlPanel/File.php?F=F_4ZRLpfMsMG3nEKq",
"https://ucsd.co1.qualtrics.com/WRQualtricsControlPanel/File.php?F=F_9mXQ1JvMOaw0F4W",
"https://ucsd.co1.qualtrics.com/WRQualtricsControlPanel/File.php?F=F_54qtwdUJz9oW1tY",
"https://ucsd.co1.qualtrics.com/WRQualtricsControlPanel/File.php?F=F_5uxgpfjOoxaNX4W",
"https://ucsd.co1.qualtrics.com/WRQualtricsControlPanel/File.php?F=F_6RPYYuJvMcSh30O",
"https://ucsd.co1.qualtrics.com/WRQualtricsControlPanel/File.php?F=F_cZ3LpvRejenG086",
"https://ucsd.co1.qualtrics.com/WRQualtricsControlPanel/File.php?F=F_9LXxmmVumVoloqO",
"https://ucsd.co1.qualtrics.com/WRQualtricsControlPanel/File.php?F=F_4ONyI16VAgi5JRk",
"https://ucsd.co1.qualtrics.com/WRQualtricsControlPanel/File.php?F=F_2i5gJkUka0rotWC",
"https://ucsd.co1.qualtrics.com/WRQualtricsControlPanel/File.php?F=F_4Ttn4MEqiEuIROC",
"https://ucsd.co1.qualtrics.com/WRQualtricsControlPanel/File.php?F=F_dnHYW3Q0M6NkReK",
"https://ucsd.co1.qualtrics.com/WRQualtricsControlPanel/File.php?F=F_4YJp0rwn4Ey2qWi",
"https://ucsd.co1.qualtrics.com/WRQualtricsControlPanel/File.php?F=F_a4v21jJftBLmbeC",
"https://ucsd.co1.qualtrics.com/WRQualtricsControlPanel/File.php?F=F_7QUmWILnf0ni1F4",
"https://ucsd.co1.qualtrics.com/WRQualtricsControlPanel/File.php?F=F_b8e6ITTXVnaACpg",
"https://ucsd.co1.qualtrics.com/WRQualtricsControlPanel/File.php?F=F_6yPymkHFybNgQWa",
"https://ucsd.co1.qualtrics.com/WRQualtricsControlPanel/File.php?F=F_9pnp5yTXVxeio3c",
"https://ucsd.co1.qualtrics.com/WRQualtricsControlPanel/File.php?F=F_01kxwAle5XoBoeq",
"https://ucsd.co1.qualtrics.com/WRQualtricsControlPanel/File.php?F=F_9uHA0w6tnibEB4q",
"https://ucsd.co1.qualtrics.com/WRQualtricsControlPanel/File.php?F=F_1Y1nutGJurGvzCe",
"https://ucsd.co1.qualtrics.com/WRQualtricsControlPanel/File.php?F=F_4Sd9yAXbp6mVNEa",
"https://ucsd.co1.qualtrics.com/WRQualtricsControlPanel/File.php?F=F_0f7bLQ1zmR76oWa",
"https://ucsd.co1.qualtrics.com/WRQualtricsControlPanel/File.php?F=F_ahD1JCg2UZH3nAa",
"https://ucsd.co1.qualtrics.com/WRQualtricsControlPanel/File.php?F=F_5ubjBUvSFA3NTo2",
"https://ucsd.co1.qualtrics.com/WRQualtricsControlPanel/File.php?F=F_6KVakul2a60crhI",
"https://ucsd.co1.qualtrics.com/WRQualtricsControlPanel/File.php?F=F_1Ystp6vKDhLEkTA",
"https://ucsd.co1.qualtrics.com/WRQualtricsControlPanel/File.php?F=F_3lPoIJmpC7xyJy6",
"https://ucsd.co1.qualtrics.com/WRQualtricsControlPanel/File.php?F=F_8cgW5bfhNpeu0ey",
"https://ucsd.co1.qualtrics.com/WRQualtricsControlPanel/File.php?F=F_8ugiNyDBgwS3JHM",
"https://ucsd.co1.qualtrics.com/WRQualtricsControlPanel/File.php?F=F_78KVcBdCGIRVz02",
"https://ucsd.co1.qualtrics.com/WRQualtricsControlPanel/File.php?F=F_24f5eHXOc1E8Cuq"), value.name = "Trial_type")
library(data.table)
queer_stimname_long <- queer_stimname %>% melt(meas = patterns("https://ucsd.co1.qualtrics.com/WRQualtricsControlPanel/File.php?F=F_bpk3XPtzPK8npH0",
"https://ucsd.co1.qualtrics.com/WRQualtricsControlPanel/File.php?F=F_es2YcbbCLrtMSmW",
"https://ucsd.co1.qualtrics.com/WRQualtricsControlPanel/File.php?F=F_4ZRLpfMsMG3nEKq",
"https://ucsd.co1.qualtrics.com/WRQualtricsControlPanel/File.php?F=F_9mXQ1JvMOaw0F4W",
"https://ucsd.co1.qualtrics.com/WRQualtricsControlPanel/File.php?F=F_54qtwdUJz9oW1tY",
"https://ucsd.co1.qualtrics.com/WRQualtricsControlPanel/File.php?F=F_5uxgpfjOoxaNX4W",
"https://ucsd.co1.qualtrics.com/WRQualtricsControlPanel/File.php?F=F_6RPYYuJvMcSh30O",
"https://ucsd.co1.qualtrics.com/WRQualtricsControlPanel/File.php?F=F_cZ3LpvRejenG086",
"https://ucsd.co1.qualtrics.com/WRQualtricsControlPanel/File.php?F=F_9LXxmmVumVoloqO",
"https://ucsd.co1.qualtrics.com/WRQualtricsControlPanel/File.php?F=F_4ONyI16VAgi5JRk",
"https://ucsd.co1.qualtrics.com/WRQualtricsControlPanel/File.php?F=F_2i5gJkUka0rotWC",
"https://ucsd.co1.qualtrics.com/WRQualtricsControlPanel/File.php?F=F_4Ttn4MEqiEuIROC",
"https://ucsd.co1.qualtrics.com/WRQualtricsControlPanel/File.php?F=F_dnHYW3Q0M6NkReK",
"https://ucsd.co1.qualtrics.com/WRQualtricsControlPanel/File.php?F=F_4YJp0rwn4Ey2qWi",
"https://ucsd.co1.qualtrics.com/WRQualtricsControlPanel/File.php?F=F_a4v21jJftBLmbeC",
"https://ucsd.co1.qualtrics.com/WRQualtricsControlPanel/File.php?F=F_7QUmWILnf0ni1F4",
"https://ucsd.co1.qualtrics.com/WRQualtricsControlPanel/File.php?F=F_b8e6ITTXVnaACpg",
"https://ucsd.co1.qualtrics.com/WRQualtricsControlPanel/File.php?F=F_6yPymkHFybNgQWa",
"https://ucsd.co1.qualtrics.com/WRQualtricsControlPanel/File.php?F=F_9pnp5yTXVxeio3c",
"https://ucsd.co1.qualtrics.com/WRQualtricsControlPanel/File.php?F=F_01kxwAle5XoBoeq",
"https://ucsd.co1.qualtrics.com/WRQualtricsControlPanel/File.php?F=F_9uHA0w6tnibEB4q",
"https://ucsd.co1.qualtrics.com/WRQualtricsControlPanel/File.php?F=F_1Y1nutGJurGvzCe",
"https://ucsd.co1.qualtrics.com/WRQualtricsControlPanel/File.php?F=F_4Sd9yAXbp6mVNEa",
"https://ucsd.co1.qualtrics.com/WRQualtricsControlPanel/File.php?F=F_0f7bLQ1zmR76oWa",
"https://ucsd.co1.qualtrics.com/WRQualtricsControlPanel/File.php?F=F_ahD1JCg2UZH3nAa",
"https://ucsd.co1.qualtrics.com/WRQualtricsControlPanel/File.php?F=F_5ubjBUvSFA3NTo2",
"https://ucsd.co1.qualtrics.com/WRQualtricsControlPanel/File.php?F=F_6KVakul2a60crhI",
"https://ucsd.co1.qualtrics.com/WRQualtricsControlPanel/File.php?F=F_1Ystp6vKDhLEkTA",
"https://ucsd.co1.qualtrics.com/WRQualtricsControlPanel/File.php?F=F_3lPoIJmpC7xyJy6",
"https://ucsd.co1.qualtrics.com/WRQualtricsControlPanel/File.php?F=F_8cgW5bfhNpeu0ey",
"https://ucsd.co1.qualtrics.com/WRQualtricsControlPanel/File.php?F=F_8ugiNyDBgwS3JHM",
"https://ucsd.co1.qualtrics.com/WRQualtricsControlPanel/File.php?F=F_78KVcBdCGIRVz02",
"https://ucsd.co1.qualtrics.com/WRQualtricsControlPanel/File.php?F=F_24f5eHXOc1E8Cuq"), value.name = "Trial_type")
View(queer_stimname_long)
queer_stimname_long <- queer_stimname %>% pivot_longer()
queer_stimname_long <- queer_stimname %>% pivot_longer(Participant)
View(queer_stimname_long)
View(queer_stimname)
View(queer_qid_long)
View(queer_qid)
View(queer)
?names_to()
?names_to
??names_to
#something else
queer_long <- queer %>% pivot_longer(cols = X1_Q36_1:X33_Q62_1, names_to = c(".value","Q3"))
#something else
queer_long <- queer %>% pivot_longer(cols = X1_Q36_1:X33_Q62_1, names_to = c(".value","Q3"), names_sep = "_")
View(queer_long)
queer_long <- queer %>%
gather(key, value, -Participant) %>%
extract(key, c("question", "loop_number"), "(Q.\\..)\\.(.)") %>%
spread(question, value)
queer_long <- queer %>%
gather(key, value) %>%
extract(key, c("question", "loop_number"), "(Q.\\..)\\.(.)") %>%
spread(question, value)

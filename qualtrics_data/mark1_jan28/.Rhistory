installed.packages()
install.packages("tidyverse")
install.packages("lme4")
install.packages("lmer")
install.packages("nearey")
install.packages("ggplot2")
install.packages("vowels")
install.packages("xlsx")
data <- read.csv("/Volumes/MEG/NYUAD-Lab-Server/Personal Files/Ben/sounds/BIPHON_test0.csv")
View(data)
install.packages("reshape")
library(reshape)
mdata <- melt(data, id=c("id","time"))
mdata <- melt(data, id=c("P1","Q1"))
install.packages("tidyr")
install.packages("magrittr")
library("tidyr")
long_DF <- data %>% gather(trial, ppt_ans, X1_P1:X365_T2_Click.Count)
head(long_DF,20)
View(data)
library(xlsx)
dat <- open.csv('/Users/bcl/Desktop/lab stuff/BIPHON_test0.csv')
dat <- read.csv('/Users/bcl/Desktop/lab stuff/BIPHON_test0.csv')
View(dat)
library(readxl)
BIPHON_test0 <- read_excel("Desktop/lab stuff/BIPHON_test0.xls")
View(BIPHON_test0)
installed.packages()
library(vowels)
library(dplyr)
gather()
install.packages('tudyr')
install.packages('tidyr')
install.packages('magritter')
install.packages('magrittr')
install.packages("magrittr")
library(tidyr)
library(magrittr)
library(readxl)
BIPHON3_qualtrics <- read_excel("Desktop/lab stuff/BIPHON3_qualtrics.xls")
View(BIPHON3_qualtrics)
BIPHON3_long <- BIPHON3_qualtrics %>% gather(Subject, Response, sub22:sub36)
View(BIPHON3_long)
write.csv(BIPHON2_long, file='/Users/bcl/Desktop/lab stuff/BIPHON3_melt.csv')
write.csv(BIPHON3_long, file='/Users/bcl/Desktop/lab stuff/BIPHON3_melt.csv')
BIPHON3_long$Response <- ifelse(BIPHON$Response ="A", "1")
BIPHON3_long$Response <- ifelse(BIPHON$Response =="A", "1")
BIPHON3_long$Response <- ifelse(BIPHON3_long$Response =="A", "1")
BIPHON3_long$Response <- ifelse(BIPHON3_long$Response == "A", "1", "B")
BIPHON3_long$Response <- ifelse(BIPHON3_long$Response == "B", "2", "A")
BIPHON3_long <- BIPHON3_qualtrics %>% gather(Subject, Response, sub22:sub36)
BIPHON3_long$Response <- ifelse(BIPHON3_long$Response == "A", "1", "2")
write.csv(BIPHON3_long, file='/Users/bcl/Desktop/lab stuff/BIPHON3_melt.csv')
library(readxl)
BIPHON3 <- read_excel("Desktop/lab stuff/BIPHON3.xls")
View(BIPHON3)
library(lme4)
BIPHON3$Nativeness <- as.factor(BIPHON$Nativeness)
BIPHON3$Nativeness <- as.factor(BIPHON3$Nativeness)
BIPHON3$Correct <- as.factor(BIPHON3$Correct)
xglmer <- glmer(Correct ~ Nativeness + (1|subject), famile = binomial, data=BIPHON3)
xglmer <- glmer(Correct ~ Nativeness + (1|Subject), famile = binomial, data=BIPHON3)
xglmer <- glmer(Correct ~ Nativeness + (1|Subject), famile = binomial, data=BIPHON3)
BIPHON3$Response <- as.factor(BIPHON3$Response)
xglmer <- glmer(Correct ~ Nativeness + (1|Subject), famile = binomial, data=BIPHON3)
xglmer <- glmer(Correct ~ Nativeness + (1|Subject), family = binomial, data=BIPHON3)
summary(xglmer)
coef(xglmer)
exp(0.9589667)
2.608999/(1+2.608999)
exp(0.9230)
2.51683/(1+2.51683)
xglmer <- glmer(Correct ~ Nativeness + X_token + (1|Subject), family = binomial, data=BIPHON3)
xglmer <- glmer(Correct ~ Nativeness + (1|Subject), family = binomial, data=BIPHON3)
summary(xglmer)
xmdl <- lm(Correct ~ Nativeness)
xmdl <- lm(Correct ~ Nativeness, data=BIPHON3)
summary(xmdl)
xmdl <- lm(Correct ~ X_token, data=BIPHON3)
mytable <- read.table(Correct,Nativeness)
mytable <- read.table(BIPHON3$Correct, BIPHON3$Nativeness)
mytable <- table(BIPHON3$Correct, BIPHON3$Nativeness)
ftable(mytable)
install.packages(gmodels)
install.packages(gmodel)
install.packages('gmodels')
library(gmodels)
CrossTab(BIPHON3$Correct, BIPHON3$Nativeness)
CrossTable(BIPHON3$Correct, BIPHON3$Nativeness)
sum(BIPHON3$Correct)
library(readxl)
BIPHON3 <- read_excel("Desktop/lab stuff/BIPHON3.xls")
View(BIPHON3)
library(readxl)
BIPHON3 <- read_excel("Desktop/lab stuff/BIPHON3.xls")
View(BIPHON3)
BIPHON_subset_iy <- subset(BIPHON3, critical_vowel_token == "iy")
BIPHON_subset_yi <- subset(BIPHON3, critical_vowel_token == "yi")
BIPHON_subset_iY <- subset(BIPHON3, critical_vowel_token == "iʏ")
BIPHON_subset_Yi <- subset(BIPHON3, critical_vowel_token == "ʏi")
BIPHON_subset_yIH <- subset(BIPHON3, critical_vowel_token == "yɪ")
BIPHON_subset_IHy <- subset(BIPHON3, critical_vowel_token == "ɪy")
BIPHON_subset_YIH <- subset(BIPHON3, critical_vowel_token == "ʏɪ")
BIPHON_subset_IHY <- subset(BIPHON3, critical_vowel_token == "ɪʏ")
BIPHON_subset_yu <- subset(BIPHON3, critical_vowel_token == "yu")
BIPHON_subset_uy <- subset(BIPHON3, critical_vowel_token == "uy")
BIPHON_subset_i_alt_y <- rbind(BIPHON_subset_iy,BIPHON_subset_yi)
BIPHON_subset_i_alt_Y <- rbind(BIPHON_subset_iY,BIPHON_subset_Yi)
BIPHON_subset_IH_alt_Y <- rbind(BIPHON_subset_IHY,BIPHON_subset_YIH)
BIPHON_subset_IH_alt_y <- rbind(BIPHON_subset_IHy,BIPHON_subset_yIH)
BIPHON_subset_u_alt_y <- rbind(BIPHON_subset_uy,BIPHON_subset_yu)
View(BIPHON_subset_i_alt_y)
res_5
res_5 <- t.test(BIPHON_subset_IH_alt_Y$Correct,BIPHON_subset_i_alt_Y$Correct)
res_5
res_6 <- t.test(BIPHON_subset_i_alt_y$Correct,BIPHON_subset_IH_alt_y$Correct)
res_6
res <- t.test(BIPHON_subset_i_alt_y$Correct,BIPHON_subset_i_alt_Y$Correct)
res
res_2 <- t.test(BIPHON_subset_IH_alt_Y$Correct,BIPHON_subset_IH_alt_y$Correct)
res_2
res_4 <- t.test(BIPHON_subset_u_alt_y$Correct,BIPHON_subset_i_alt_y$Correct)
res_4
BIPHON_subset_uø <- subset(BIPHON3, critical_vowel_token == "uø")
BIPHON_subset_øu <- subset(BIPHON3, critical_vowel_token == "øu")
BIPHON_subset_ʊø <- subset(BIPHON3, critical_vowel_token == "ʊø")
BIPHON_subset_øʊ <- subset(BIPHON3, critical_vowel_token == "øʊ")
BIPHON_subset_ɯu <- subset(BIPHON3, critical_vowel_token == "ɯu")
BIPHON_subset_uɯ <- subset(BIPHON3, critical_vowel_token == "uɯ")
BIPHON_subset_ʊɯ <- subset(BIPHON3, critical_vowel_token == "ʊɯ")
BIPHON_subset_ɯʊ <- subset(BIPHON3, critical_vowel_token == "ɯʊ")
View(BIPHON_subset_ʊø)
View(BIPHON_subset_ʊø)
BIPHON_subset_u_alt_ø <- rbind(BIPHON_subset_uø,BIPHON_subset_øu)
BIPHON_subset_ʊ_alt_ø <- rbind(BIPHON_subset_ʊø,BIPHON_subset_øʊ)
BIPHON_subset_u_alt_ɯ <- rbind(BIPHON_subset_ɯu,BIPHON_subset_uɯ)
BIPHON_subset_ʊ_alt_ɯ <- rbind(BIPHON_subset_ʊɯ,BIPHON_subset_ɯʊ)
res_10 <- t.test(BIPHON_subset_u_alt_ø$Correct,BIPHON_subset_ʊ_alt_ø$Correct)
res_10
res_11 <- t.test(BIPHON_subset_u_alt_ɯ$Correct,BIPHON_subset_ʊ_alt_ɯ$Correct)
res_11
res_12 <- t.test(BIPHON_subset_u_alt_ɯ$Correct,BIPHON_subset_u_alt_ø$Correct)
res_12
res_13 <- t.test(BIPHON_subset_ʊ_alt_ø$Correct,BIPHON_subset_ʊ_alt_ɯ$Correct)
res_13
library(readxl)
vowel_formants_reduced <- read_excel("Desktop/lab stuff/vowel_formants_reduced.xls")
View(vowel_formants_reduced)
library(ggplot2)
vowel_formants_reduced$vowel <- as.factor(vowel_formants_reduced$vowel)
ggplot(data=vowel_formants_reduced, aes(x=F2, y=F1)) +
geom_point(aes(color=vowel)) +
scale_x_reverse(position = "top") +
scale_y_reverse(position = "right")
ggplot(data=vowel_formants_reduced, aes(x=F2, y=F1)) +
geom_text(aes(label=vowel, color=vowel)) +
scale_x_reverse(position = "top") +
scale_y_reverse(position = "right")
ggplot(data=vowel_formants_reduced, aes(x=F2, y=F1)) +
geom_text(aes(label=vowel, color=vowel, size=14)) +
scale_x_reverse(position = "top") +
scale_y_reverse(position = "right")
ggplot(data=vowel_formants_reduced, aes(x=F2, y=F1)) +
geom_text(aes(label=vowel, color=vowel), size=12) +
scale_x_reverse(position = "top") +
scale_y_reverse(position = "right")
ggplot(data=vowel_formants_reduced, aes(x=F2, y=F1)) +
geom_text(aes(label=vowel, color=vowel), size=10) +
scale_x_reverse(position = "top") +
scale_y_reverse(position = "right")
ggplot(data=vowel_formants_reduced, aes(x=F2, y=F1)) +
geom_text(aes(label=vowel, color=vowel), size=10) +
scale_x_reverse(position = "top") +
scale_y_reverse(position = "right") + theme(title="Vowels")
ggplot(data=vowel_formants_reduced, aes(x=F2, y=F1)) +
geom_text(aes(label=vowel, color=vowel), size=10) +
scale_x_reverse(position = "top") +
scale_y_reverse(position = "right") + theme(title = Vowels)
ggplot(data=vowel_formants_reduced, aes(x=F2, y=F1)) +
geom_text(aes(label=vowel, color=vowel), size=10) +
scale_x_reverse(position = "top") +
scale_y_reverse(position = "right") + theme(title = 'Vowels'')
ggplot(data=vowel_formants_reduced, aes(x=F2, y=F1)) +
geom_text(aes(label=vowel, color=vowel), size=10) +
scale_x_reverse(position = "top") +
scale_y_reverse(position = "right")
ggplot(data=vowel_formants_reduced, aes(x=F2, y=F1)) +
geom_text(aes(label=vowel, color=vowel), size=10) +
scale_x_reverse(position = "top") +
scale_y_reverse(position = "right") + theme(title = 'Vowels'')
ggplot(data=vowel_formants_reduced, aes(x=F2, y=F1)) +
geom_text(aes(label=vowel, color=vowel), size=10) +
scale_x_reverse(position = "top") +
scale_y_reverse(position = "right") + theme(title = 'Vowels')
ggplot(data=vowel_formants_reduced, aes(x=F2, y=F1)) +
geom_text(aes(label=vowel, color=vowel), size=10) +
scale_x_reverse(position = "top") +
scale_y_reverse(position = "right") + theme(title = element_text('Vowels')
ggplot(data=vowel_formants_reduced, aes(x=F2, y=F1)) +
geom_text(aes(label=vowel, color=vowel), size=10) +
scale_x_reverse(position = "top") +
scale_y_reverse(position = "right") + theme(title = element_text('Vowels'))
ggplot(data=vowel_formants_reduced, aes(x=F2, y=F1)) +
geom_text(aes(label=vowel, color=vowel), size=10) +
scale_x_reverse(position = "top") +
scale_y_reverse(position = "right")
ggplot(data=vowel_formants_reduced, aes(x=F2, y=F1)) +
geom_text(aes(label=vowel, color=vowel), size=8) +
scale_x_reverse(position = "top") +
scale_y_reverse(position = "right")
library(readxl)
vowel_formants_reduced <- read_excel("Desktop/lab stuff/vowel_formants_reduced.xls")
View(vowel_formants_reduced)
ggplot(data=vowel_formants_reduced, aes(x=F2, y=F1)) +
geom_text(aes(label=vowel, color=vowel), size=8) +
scale_x_reverse(position = "top") +
scale_y_reverse(position = "right")
sig <- table(1,2)
sig
sig <- table(1,2,3)
sig
sig <- table(1,5)
sig
sig <- table(1:3,5)
BIPHON_subset_Yu <- subset(BIPHON3, critical_vowel_token == "ʏu")
BIPHON_subset_uY <- subset(BIPHON3, critical_vowel_token == "uʏ")
BIPHON_subset_u_alt_Y <- rbind(BIPHON_subset_Yu,BIPHON_subset_uY)
res_15 <- t.test(BIPHON_subset_u_alt_Y$Correct,BIPHON_subset_u_alt_y$Correct)
View(BIPHON_subset_uY)
View(BIPHON_subset_uY)
BIPHON3
BIPHON_subset_Yu <- subset(BIPHON3, critical_vowel_token == "ʏu")
BIPHON3$critical_vowel_token
library(readxl)
BIPHON3 <- read_excel("Desktop/lab stuff/BIPHON3_plusdist.xlsx")
View(BIPHON3)
BIPHON_native ,- subset(BIPHON3, Nativeness == "1")
BIPHON_native <- subset(BIPHON3, Nativeness == "1")
BIPHON_nonnative <- subset(BIPHON3, Nativeness == "0")
head(BIPHON3)
nonnative_mdl <- lmer(Correct ~ critical_vowel_distance +(1|Subject), data=BIPHON3)
library(lme4)
nonnative_mdl <- lmer(Correct ~ critical_vowel_distance +(1|Subject), data=BIPHON3)
nonnative_mdl <- lmer(Correct ~ critical_vowel_distance...30 +(1|Subject), data=BIPHON3)
nonnative_mdl <- lmer(Correct ~ critical_vowel_dist +(1|Subject), data=BIPHON3)
summary(nonnative_mdl)
nonnative_mdl <- lmer(Correct ~ critical_vowel_dist +(1|Subject), data=BIPHON3, family="binomial")
nonnative_mdl <- glmer(Correct ~ critical_vowel_dist +(1|Subject), data=BIPHON3, family="binomial")
str(BIPHON3)
BIPHON_nonnative$Correct = as.factor(BIPHON_nonnative$Correct)
str(BIPHON3)
str(BIPHON3_nonnative)
str(BIPHON_nonnative)
nonnative_mdl <- glmer(Correct ~ critical_vowel_dist +(1|Subject), data=BIPHON3, family="binomial")
View(BIPHON_nonnative)
nonnative_mdl <- glmer(Correct ~ critical_vowel_dist +(1|Subject), data=BIPHON3, family="logit")
nonnative_mdl <- glmer(Correct ~ critical_vowel_dist +(1|Subject), data=BIPHON3, family="binomial"(link='logit'))
library(lmerTest)
library(dplyr) # this checks for normality
library(ggpubr) # this plots normality
install.packages("ggpubr")
set.seed(1234)
dplyr::sample_n(BIPHON3, 15)
ggqqplot(BIPHON3$Correct) # make qq plot
library(ggpubr)
set.seed(1234)
dplyr::sample_n(BIPHON3, 15)
ggqqplot(BIPHON3$Correct) # make qq plot
set.seed(1234)
dplyr::sample_n(BIPHON3, 15)
ggqqplot(BIPHON3$critical_vowel_dist) # make qq plot
ggdensity(BIPHON3$critical_vowel_dist,  # make density plot
main = "Density plot of RT",
xlab = "Reaction Time")
shapiro.test(BIPHON3$critical_vowel_dist) # test distribution against normal distribution
nonnative_mdl <- glmer(Correct ~ critical_vowel_dist +(1|Subject), data=BIPHON3, family=binomial(l))
nonnative_mdl <- glmer(Correct ~ critical_vowel_dist +(1|Subject), data=BIPHON3, family=binomial(link=logit))
nonnative_mdl <- glmer(Correct ~ critical_vowel_dist +(1|Subject), data=BIPHON3, family=binomial(link="logit"))
str(BIPHON_nonnative)
nonnative_mdl <- glme(Correct ~ critical_vowel_dist, data=BIPHON3, family=binomial(link="logit"))
nonnative_mdl <- lme(Correct ~ critical_vowel_dist, data=BIPHON3, family=binomial(link="logit"))
nonnative_mdl <- glm(Correct ~ critical_vowel_dist, data=BIPHON3, family=binomial(link="logit"))
nonnative_mdl
summary(nonnative_mdl)
View(nonnative_mdl)
View(nonnative_mdl)
nonnative_mdl <- glmer(Correct ~ critical_vowel_dist +(1|Subject), data=BIPHON3, family=binomial(link="logit"), glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 100000)))
nonnative_mdl <- glm(Correct ~ critical_vowel_dist, data=BIPHON3, family=binomial(link="logit"))
anova(nonnative_mdl)
Anova(nonnative_mdl)
install.package('car')
install.packages('car')
library('car')
install.packages("openxlsx")
library('car')
Anova(nonnative_mdl)
nonnative_mdl <- glmer(Correct ~ critical_vowel_dist +(1|Subject), data=BIPHON3, family=binomial(link="logit"), glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e5)))
nonnative_mdl <- glmer(Correct ~ critical_vowel_dist, data=BIPHON3, family=binomial(link="logit"), glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e5)))
nonnative_mdl <- glmer(Correct ~ critical_vowel_dist + (1|Subject), data=BIPHON3, family=binomial(link="logit"), glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e5)))
str(BIPHON_nonnative)
BIPHON_nonnative$Subject = as.factor(BIPHON_nonnative$Subject)
nonnative_mdl <- glmer(Correct ~ critical_vowel_dist + (1|Subject), data=BIPHON3, family=binomial(link="logit"), glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e5)))
nonnative_mdl <- glmer(Correct ~ critical_vowel_dist + (1|Subject), data=BIPHON_nonnative, family=binomial(link="logit"), glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e5)))
nonnative_mdl <- glmer(Correct ~ critical_vowel_dist + (1|unique_id), data=BIPHON_nonnative, family=binomial(link="logit"), glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e5)))
str(BIPHON_nonnative)
BIPHON_nonnative$unique_id = as.factor(BIPHON_nonnative$unique_id)
nonnative_mdl <- glmer(Correct ~ critical_vowel_dist + (1|unique_id), data=BIPHON_nonnative, family=binomial(link="logit"), glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e5)))
ggplot(data=vowel_formants_reduced, aes(x=F2, y=F1)) +
geom_text(aes(label=vowel, color=vowel), size=8) +
scale_x_reverse(position = "top") +
scale_y_reverse(position = "right")
library(ggplot)
library(ggplot2)
library(ggplot)
ggplot(data=vowel_formants_reduced, aes(x=F2, y=F1)) +
geom_text(aes(label=vowel, color=vowel), size=8) +
scale_x_reverse(position = "top") +
scale_y_reverse(position = "right")
View(vowel_formants_reduced)
library(readxl)
vowel_formants_reduced_2 <- read_excel("Desktop/lab stuff/vowel_formants_reduced_2.xls")
View(vowel_formants_reduced_2)
ggplot(data=vowel_formants_reduced_2, aes(x=F2, y=F1)) +
geom_text(aes(label=vowel, color=vowel), size=8) +
scale_x_reverse(position = "top") +
scale_y_reverse(position = "right")
install.packages("wesanderson")
## Queer Speech Data Analysis and Visualization Treasure Trove
## Author: Ben Lang, blang@ucsd.edu
# library(lmerTest)
library(plyr)
library(dplyr) # this checks for normality
# library(ggpubr) # this plots normality
library(magrittr)
# library(effects)
# library(ggplot2)
library(tidyr)
# library(scales)
library(reshape2)
# library(lme4)
# library(emmeans)
library(forcats)
# library(psycho)
library(tibble)
library(janitor)
library(data.table)
setwd('/Users/bcl/Documents/GitHub/queer_speech/qualtrics_data/mark1_jan28/')
options(stringsAsFactors=F)
queer = read.csv('/Volumes/GoogleDrive/My Drive/Comps/qualtrics_data/mark1_jan28/queer-speech_February 23, 2022_16.11.csv')
#cleaning data down to just ratings, trial type, and stimulus ID
# queer <- subset(queer, Status == 0 | Status == "Response Type") # just for if there's people that don't complete the survey
queer <- select(queer, -contains(c("First.Click","Last.Click","Page.Submit","Click.Count"))) # remove all the time counts, can add in later if needed
# queer$Participant <- 1:nrow(queer)-1
queer <- select(queer, -c(StartDate, EndDate, ResponseId, UserLanguage, Consent, HC2, RecipientLastName, RecipientFirstName, RecipientEmail, ExternalReference, LocationLatitude, LocationLongitude, DistributionChannel, IPAddress, Progress, Status, Finished, RecordedDate, Duration..in.seconds.))
queer <- select(queer, -c(P1_1:P5_1)) # eliminate practice questions
# queer <- select(queer, -c(D1:id)) # eliminate practice questions
# queer <- queer %>% relocate(D2:Q47, .before = 1)
# queer <- queer %>% relocate(Q56, .before = 1)
queer <- queer[-2,]
queer[1,] <- gsub(".*- (.+) -.*", "\\1", queer[1,]) # works on iMac, for some reason not on laptop, supposed to just grab URLs
queer <- add_column(queer, Participant = 1:nrow(queer)-1, .before = 1)
# splitting dfs to then concatenate
queer_qid <- queer[-1,]
ncol(queer_qid)
queer_qid_long <- queer_qid %>% gather(Qualtrics_Trial_Num, Rating, X1_Q36_1:X33_Q62_1)
# sanity check, should come out to 66 so that it's how many trials were responded to, divided by the number of conditions (3)
trial_counts <- queer_qid_long %>% group_by(Qualtrics_Trial_Num) %>% count(Qualtrics_Trial_Num)
nrow(trial_counts)/3
#queer[1,] <- queer %>% separate(X1_Q36_1:X33_Q62_1, Question, Token)
## second match, must remove extra columns to match long data above
queer_stimname <- select(queer, -c(D1:id, HC1)) # eliminate practice questions
queer_stimname <- row_to_names(queer_stimname, row_number = 1)
ncol(queer_stimname)
names(queer_stimname)[names(queer_stimname) == '0'] <- 'Participant'
names(queer_stimname) <- make.unique(names(queer_stimname), sep="*")
queer_stimname_long <- queer_stimname %>% gather(Trial_Type, Rating, -Participant)
# must be same length
nrow(queer_qid_long)
nrow(queer_stimname_long)
# remove duplicates columns from one, then merge together
queer_qid_long <- select(queer_qid_long, -c(Participant, Rating))
merged_queer <- bind_cols(queer_stimname_long, queer_qid_long)
## rename conditions
merged_queer$Qualtrics_Trial_Num[merged_queer$Qualtrics_Trial_Num %like% "Q36"] <- 'gender_id'
merged_queer$Qualtrics_Trial_Num[merged_queer$Qualtrics_Trial_Num %like% "Q60"] <- 'gender_id'
merged_queer$Qualtrics_Trial_Num[merged_queer$Qualtrics_Trial_Num %like% "Q29"] <- 'sexual_orientation'
merged_queer$Qualtrics_Trial_Num[merged_queer$Qualtrics_Trial_Num %like% "Q61"] <- 'sexual_orientation'
merged_queer$Qualtrics_Trial_Num[merged_queer$Qualtrics_Trial_Num %like% "Q30"] <- 'voice_id'
merged_queer$Qualtrics_Trial_Num[merged_queer$Qualtrics_Trial_Num %like% "Q62"] <- 'voice_id'
names(merged_queer)[names(merged_queer) == 'Qualtrics_Trial_Num'] <- 'Condition'
## remove uniqueness
matches = read.csv('matches_queer_speech.csv')
merged_queer <- merged_queer %>% mutate(Trial_Type = gsub("\\*1", "", Trial_Type))
merged_queer <- merged_queer %>% mutate(Trial_Type = gsub("\\*2", "", Trial_Type))
## merged the two dfs into big boi
matched_queer <- join(merged_queer, matches, by = "Trial_Type")
matched_queer <- select(matched_queer, -c(url, id, X, Trial_Type))
names(matched_queer)[names(matched_queer) == 'phon'] <- 'WAV'
matched_queer$Rating <- as.numeric(matched_queer$Rating)
### filter out D1, D2, HC1, D5, rename everything
# do some subsetting to find out how many people are excluded based on D1, D2, D5, HC1
# now do teh actual filtering
matched_queer <- subset(matched_queer, D1 == "Yes")
matched_queer <- subset(matched_queer, D2 == "Yes")
matched_queer <- subset(matched_queer, HC1 == "Yes")
matched_queer <- subset(matched_queer, D5 == "No")
matched_queer <- select(matched_queer, -c(F1, F2, D1, D2, HC1, D5))
names(matched_queer)[names(matched_queer) == 'D9_1'] <- 'participant_gender_id'
names(matched_queer)[names(matched_queer) == 'D10_1'] <- 'participant_sexual_orientation'
names(matched_queer)[names(matched_queer) == 'D11_1'] <- 'participant_voice_id'
names(matched_queer)[names(matched_queer) == 'D12_1'] <- 'participant_cis_trans'
names(matched_queer)[names(matched_queer) == 'D13'] <- 'participant_gender_pso_free_response'
names(matched_queer)[names(matched_queer) == 'PQ1_1'] <- 'participant_prox_social'
names(matched_queer)[names(matched_queer) == 'PQ2_1'] <- 'participant_prox_affiliation'
names(matched_queer)[names(matched_queer) == 'PQ3_1'] <- 'participant_prox_media'
names(matched_queer)[names(matched_queer) == 'D3'] <- 'participant_other_langs'
names(matched_queer)[names(matched_queer) == 'D4'] <- 'participant_age'
names(matched_queer)[names(matched_queer) == 'D6'] <- 'participant_race'
names(matched_queer)[names(matched_queer) == 'D7'] <- 'participant_race_hispanic'
names(matched_queer)[names(matched_queer) == 'D8'] <- 'participant_race_free_response'
### same as csv for analysis or plotting elsewhere
write.csv(matched_queer, "/Users/bcl/Documents/GitHub/queer_speech/qualtrics_data/mark1_jan28/matched_queer.csv", row.names=FALSE)
# write.csv(queer_stimname, "/Users/bcl/Documents/GitHub/queer_speech/qualtrics_data/mark1_jan28/queer_stimname.csv", row.names=FALSE)
